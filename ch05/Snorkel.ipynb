{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Snorkel\n",
    "\n",
    "In this notebook we will use Snorkel to enrich our data such that tags with between 500-2,000 examples will be labeled using weak supervision to produce labels for enough examples to allow us to train an accurate full model that includes these new labels.\n",
    "\n",
    "More information about Snorkel can be found at [Snorkel.org](https://www.snorkel.org/) :) For a basic introduction to Snorkel, see the [Spam Tutorial](http://syndrome:8888/notebooks/snorkel-tutorials/spam/01_spam_tutorial.ipynb). For an introduction to Multi-Task Learning (MTL), see [Multi-Task Tutorial](http://syndrome:8888/notebooks/snorkel-tutorials/multitask/multitask_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snorkel Introduction\n",
    "\n",
    "from collections import OrderedDict \n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cupy\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import random\n",
    "import snorkel\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Make reproducible\n",
    "random.seed(1337)\n",
    "\n",
    "# Turn off TensorFlow logging messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"1337\"\n",
    "\n",
    "# Show wide columns\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_LIMIT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    'questions': {\n",
    "        'local': '../data/stackoverflow/Questions.Tags.{}.parquet',\n",
    "        's3': 's3://stackoverflow-events/08-05-2019/Questions.Tags.{}.parquet',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define a set of paths for each step for local and S3\n",
    "PATH_SET = 'local' # 's3'\n",
    "\n",
    "path = PATHS['questions'][PATH_SET].format(TAG_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Examples for Augmentation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.read_parquet(\n",
    "    path, \n",
    "    engine='pyarrow',\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Examples for Augmentation in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_PostId</th>\n",
       "      <th>_AcceptedAnswerId</th>\n",
       "      <th>_Body</th>\n",
       "      <th>_Code</th>\n",
       "      <th>_Tags</th>\n",
       "      <th>_Label</th>\n",
       "      <th>_AnswerCount</th>\n",
       "      <th>_CommentCount</th>\n",
       "      <th>_FavoriteCount</th>\n",
       "      <th>_OwnerUserId</th>\n",
       "      <th>...</th>\n",
       "      <th>_AccountId</th>\n",
       "      <th>_UserId</th>\n",
       "      <th>_UserDisplayName</th>\n",
       "      <th>_UserDownVotes</th>\n",
       "      <th>_UserLocation</th>\n",
       "      <th>_ProfileImageUrl</th>\n",
       "      <th>_UserReputation</th>\n",
       "      <th>_UserUpVotes</th>\n",
       "      <th>_UserViews</th>\n",
       "      <th>_UserWebsiteUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415580</td>\n",
       "      <td>415635</td>\n",
       "      <td>Regex Named Groups in Java It is my understanding that the  package does not have support for named groups (  so can anyone point me towards a third-party library that does?\\nI've looked at jregex but its last release was in 2002 and it didn't work for me (admittedly I only tried briefly) under ...</td>\n",
       "      <td>java.regex</td>\n",
       "      <td>[java, regex]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>444</td>\n",
       "      <td>...</td>\n",
       "      <td>355</td>\n",
       "      <td>444</td>\n",
       "      <td>Dan</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2767</td>\n",
       "      <td>298</td>\n",
       "      <td>255</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2373579</td>\n",
       "      <td>2373869</td>\n",
       "      <td>Parsing StarTeam command line client output I'm trying to write a Perl script that will parse the output of the stcmd.exe (the StarTeam command line client) hist command. I'm getting the history for every file in a view and the output looks something like this:\\nFolder: The View Name  (working d...</td>\n",
       "      <td># $hist contains the stcmd output in the format above\\nwhile($hist =~ /History for: (?&lt;filename&gt;.)/s)\\n{\\n    # Record filename somewhere with $+{filename}\\n\\n    while($hist =~ /^Revision: (?&lt;file_rev&gt;\\S+) View: (?&lt;view_name&gt;.+) Branch Revision: (?&lt;branch_rev&gt;\\S+).\\nAuthor: (?&lt;author&gt;.*) Date: ...</td>\n",
       "      <td>[regex, perl, starteam]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>...</td>\n",
       "      <td>402</td>\n",
       "      <td>510</td>\n",
       "      <td>Evan Shaw</td>\n",
       "      <td>11</td>\n",
       "      <td>Auckland, New Zealand</td>\n",
       "      <td>None</td>\n",
       "      <td>17252</td>\n",
       "      <td>174</td>\n",
       "      <td>1078</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5346913</td>\n",
       "      <td>5347047</td>\n",
       "      <td>Calling VirtualProtect on a mapped file I'm using the CreateFileMapping and MapViewOfFile functions to map a file into memory. After a certain point, I call VirtualProtect to change its protection from read-only to read and write. This call fails and GetLastError gives ERROR_INVALID_PARAMETER.\\n...</td>\n",
       "      <td>#include &lt;stdio.h&gt;\\n#include &lt;stdlib.h&gt;\\n#include &lt;windows.h&gt;\\n\\nint main() {\\n    HANDLE fd, md;\\n    char *addr;\\n    DWORD old;\\n    BOOL ok;\\n\\n    fd = CreateFile(\"filename\", GENERIC_READ|GENERIC_WRITE, 0, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL);\\n    md = CreateFileMapping(fd, NU...</td>\n",
       "      <td>[c, windows, winapi]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>...</td>\n",
       "      <td>402</td>\n",
       "      <td>510</td>\n",
       "      <td>Evan Shaw</td>\n",
       "      <td>11</td>\n",
       "      <td>Auckland, New Zealand</td>\n",
       "      <td>None</td>\n",
       "      <td>17252</td>\n",
       "      <td>174</td>\n",
       "      <td>1078</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _PostId  _AcceptedAnswerId  \\\n",
       "0   415580             415635   \n",
       "1  2373579            2373869   \n",
       "2  5346913            5347047   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         _Body  \\\n",
       "0  Regex Named Groups in Java It is my understanding that the  package does not have support for named groups (  so can anyone point me towards a third-party library that does?\\nI've looked at jregex but its last release was in 2002 and it didn't work for me (admittedly I only tried briefly) under ...   \n",
       "1  Parsing StarTeam command line client output I'm trying to write a Perl script that will parse the output of the stcmd.exe (the StarTeam command line client) hist command. I'm getting the history for every file in a view and the output looks something like this:\\nFolder: The View Name  (working d...   \n",
       "2  Calling VirtualProtect on a mapped file I'm using the CreateFileMapping and MapViewOfFile functions to map a file into memory. After a certain point, I call VirtualProtect to change its protection from read-only to read and write. This call fails and GetLastError gives ERROR_INVALID_PARAMETER.\\n...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         _Code  \\\n",
       "0                                                                                                                                                                                                                                                                                                   java.regex   \n",
       "1  # $hist contains the stcmd output in the format above\\nwhile($hist =~ /History for: (?<filename>.)/s)\\n{\\n    # Record filename somewhere with $+{filename}\\n\\n    while($hist =~ /^Revision: (?<file_rev>\\S+) View: (?<view_name>.+) Branch Revision: (?<branch_rev>\\S+).\\nAuthor: (?<author>.*) Date: ...   \n",
       "2  #include <stdio.h>\\n#include <stdlib.h>\\n#include <windows.h>\\n\\nint main() {\\n    HANDLE fd, md;\\n    char *addr;\\n    DWORD old;\\n    BOOL ok;\\n\\n    fd = CreateFile(\"filename\", GENERIC_READ|GENERIC_WRITE, 0, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL);\\n    md = CreateFileMapping(fd, NU...   \n",
       "\n",
       "                     _Tags  _Label  _AnswerCount  _CommentCount  \\\n",
       "0            [java, regex]       0             6              2   \n",
       "1  [regex, perl, starteam]       0             4              0   \n",
       "2     [c, windows, winapi]       0             3              2   \n",
       "\n",
       "   _FavoriteCount  _OwnerUserId  ... _AccountId  _UserId  _UserDisplayName  \\\n",
       "0              46           444  ...        355      444               Dan   \n",
       "1               0           510  ...        402      510         Evan Shaw   \n",
       "2               2           510  ...        402      510         Evan Shaw   \n",
       "\n",
       "  _UserDownVotes          _UserLocation  _ProfileImageUrl _UserReputation  \\\n",
       "0             48                   None              None            2767   \n",
       "1             11  Auckland, New Zealand              None           17252   \n",
       "2             11  Auckland, New Zealand              None           17252   \n",
       "\n",
       "   _UserUpVotes _UserViews _UserWebsiteUrl  \n",
       "0           298        255            None  \n",
       "1           174       1078                  \n",
       "2           174       1078                  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Programming Language Extraction Example\") \\\n",
    "    .config('spark.dynamicAllocation.enabled', True) \\\n",
    "    .config('spark.shuffle.service.enabled', True) \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "path = PATHS['questions']['local'].format(TAG_LIMIT)\n",
    "\n",
    "question_df = spark.read.parquet(path)\n",
    "question_df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable spaCy GPU Support\n",
    "\n",
    "That is, if you have a GPU and are using Pandas. PySpark can't use a GPU yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a spaCy [`Language`](https://spacy.io/api/language) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import merge_entities\n",
    "\n",
    "# Download the spaCy english model\n",
    "spacy.cli.download('en_core_web_lg')\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"vectors\"])\n",
    "\n",
    "# Merge multi-token entities together\n",
    "nlp.add_pipe(merge_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring spaCy\n",
    "\n",
    "Below we use print statements and the visualization tool  `spacy.displacy` to render parsed objects for an example document. First we iterate the spaCy  [`Token`s](https://spacy.io/api/token) that make up the [`Doc`](https://spacy.io/api/doc) and print the text and the string defining their part-of-speech. \n",
    "\n",
    "We’ll be using these parts of speech to write Labeling Functions using spaCy pattern matching. It will be very useful to know the part of speech we’re looking for in our entities - almost exclusively proper nouns - `PROPN` - and quite often of the pattern `VERB-ADP-PROPN`, which we’ll see below.\n",
    "\n",
    "Next we use `spacy.displacy` to visualize the parse tree of dependencies between words as well as the entities detected in the sentence. This gives a rough idea of the structure that a spaCy `Doc` has for us to use. It also creates dense vectors based on embeddings for the words and the entire document, which we can use to create LFs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('program', 'NOUN'), ('to', 'PART'), ('do', 'AUX'), ('payroll', 'NOUN'), ('was', 'AUX'), ('written', 'VERB'), ('in', 'ADP'), ('C++', 'PROPN'), ('and', 'CCONJ'), ('Perl', 'PROPN'), ('.', 'PUNCT')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a0526f507be54f2f9258b6fb48d22eaa-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">program</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">payroll</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">written</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">C++</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">Perl.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-0\" stroke-width=\"2px\" d=\"M62,137.0 62,122.0 134.0,122.0 134.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,139.0 L58,131.0 66,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-1\" stroke-width=\"2px\" d=\"M152,137.0 152,92.0 590.0,92.0 590.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M152,139.0 L148,131.0 156,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-2\" stroke-width=\"2px\" d=\"M242,137.0 242,122.0 314.0,122.0 314.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M242,139.0 L238,131.0 246,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-3\" stroke-width=\"2px\" d=\"M152,137.0 152,107.0 317.0,107.0 317.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M317.0,139.0 L321.0,131.0 313.0,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-4\" stroke-width=\"2px\" d=\"M332,137.0 332,122.0 404.0,122.0 404.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M404.0,139.0 L408.0,131.0 400.0,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-5\" stroke-width=\"2px\" d=\"M512,137.0 512,122.0 584.0,122.0 584.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,139.0 L508,131.0 516,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-6\" stroke-width=\"2px\" d=\"M602,137.0 602,122.0 674.0,122.0 674.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M674.0,139.0 L678.0,131.0 670.0,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-7\" stroke-width=\"2px\" d=\"M692,137.0 692,122.0 764.0,122.0 764.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M764.0,139.0 L768.0,131.0 760.0,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-8\" stroke-width=\"2px\" d=\"M782,137.0 782,122.0 854.0,122.0 854.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M854.0,139.0 L858.0,131.0 850.0,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a0526f507be54f2f9258b6fb48d22eaa-0-9\" stroke-width=\"2px\" d=\"M782,137.0 782,107.0 947.0,107.0 947.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a0526f507be54f2f9258b6fb48d22eaa-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M947.0,139.0 L951.0,131.0 943.0,131.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The program to do payroll was written in \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    C++\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Perl\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "s = 'The program to do payroll was written in C++ and Perl.'\n",
    "d = nlp(s)\n",
    "tups = []\n",
    "for t in d:\n",
    "    tups.append((t.text, t.pos_))\n",
    "\n",
    "# Print words/parts-of-speech\n",
    "print([x for x in tups])\n",
    "\n",
    "# Render image diagrams\n",
    "displacy.render(d, style='dep', options={'compact': True, 'collapse_punct': True, 'distance': 90}, )\n",
    "displacy.render(d, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Pandas, produce records with their left/right tokens for all entities in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Pandas - \n",
    "#\n",
    "window = 5\n",
    "candidates = []\n",
    "for index, row in df.iterrows():\n",
    "    doc = nlp(row['_Body'])\n",
    "    re_doc_1 = nlp(row['body'])\n",
    "    re_doc_2 = nlp(row['body'])\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        rec = {}\n",
    "        rec['body'] = doc.text\n",
    "        rec['entity'] = ent\n",
    "        rec['entity_text'] = ent.text\n",
    "        rec['entity_start'] = ent.start\n",
    "        rec['entity_end'] = ent.end\n",
    "        rec['ent_type'] = ent.label_\n",
    "\n",
    "        left_token_start = max(0, ent.start - 1 - window)\n",
    "        left_token_end = ent.start\n",
    "        rec['left_tokens_text'] = [x.text for x in doc[left_token_start : left_token_end]]\n",
    "        rec['left_text'] = re_doc_1[left_token_start : left_token_end].merge()\n",
    "\n",
    "        right_token_start = min(ent.end, len(doc) - 1)\n",
    "        right_token_end = min(ent.end + window, len(doc) - 1)\n",
    "        rec['right_tokens_text'] = [x.text for x in doc[right_token_start : right_token_end]]\n",
    "        rec['right_text'] = re_doc_2[right_token_start : right_token_end].merge()\n",
    "\n",
    "        rec['wikidata_id'] = ent.kb_id\n",
    "        \n",
    "        rec['original_index'] = index\n",
    "        rec['label'] = 0\n",
    "\n",
    "        candidates.append(rec)\n",
    "\n",
    "df_out = pd.DataFrame(candidates)\n",
    "df_out = df_out.reindex().sort_index()\n",
    "\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In PySpark, produce records with their left/right tokens for all entities in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import merge_entities\n",
    "\n",
    "def prepare_docs(rows, window: int=5):\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_lg\", disable=[\"vectors\"])\n",
    "    nlp.add_pipe(merge_entities)\n",
    "    \n",
    "    recs = []\n",
    "    \n",
    "    for row in rows:\n",
    "        \n",
    "        doc = nlp(row._Body)\n",
    "        re_doc_1 = nlp(row._Body)\n",
    "        re_doc_2 = nlp(row._Body)\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            rec = {}\n",
    "            rec['body'] = doc.text\n",
    "\n",
    "            rec['entity_text'] = ent.text\n",
    "            rec['entity_start'] = ent.start\n",
    "            rec['entity_end'] = ent.end\n",
    "            rec['ent_type'] = ent.label_\n",
    "\n",
    "            left_token_start = max(0, ent.start - 1 - window)\n",
    "            left_token_end = ent.start\n",
    "            rec['left_tokens_text'] = [x.text for x in doc[left_token_start : left_token_end]]\n",
    "\n",
    "            left_merged_token = re_doc_1[left_token_start: left_token_end].merge()\n",
    "            rec['left_text'] = left_merged_token.text if left_merged_token else ''\n",
    "            del left_token_start\n",
    "            del left_token_end\n",
    "            \n",
    "            right_token_start = min(ent.end, len(doc) - 1)\n",
    "            right_token_end = min(ent.end + window, len(doc) - 1)\n",
    "            rec['right_tokens_text'] = [x.text for x in doc[right_token_start : right_token_end]]\n",
    "            \n",
    "            right_merged_token = re_doc_2[right_token_start: right_token_end].merge()\n",
    "            rec['right_text'] = right_merged_token.text if right_merged_token else ''\n",
    "            del right_token_start\n",
    "            del right_token_end\n",
    "            \n",
    "            rec['wikidata_id'] = ent.kb_id\n",
    "            rec['label'] = 0\n",
    "            \n",
    "            recs.append(rec)\n",
    "            del ent\n",
    "            \n",
    "        del doc\n",
    "        del re_doc_1\n",
    "        del re_doc_2\n",
    "    \n",
    "    return recs\n",
    "\n",
    "\n",
    "entity_df = question_df.repartition(48).rdd.mapPartitions(prepare_docs)\n",
    "\n",
    "entity_df = entity_df.sortBy(lambda x: random.random())\n",
    "entity_df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Gold Labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = pd.read_csv('../../data/text_extractions.one_file.df_out.gold.labeled.final.csv')\n",
    "\n",
    "# Drop the index column, we have an index set\n",
    "df_gold = df_gold.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "df_gold['left_tokens_text'] = df_gold['left_tokens_text'].apply(lambda x: ast.literal_eval(x))\n",
    "df_gold['right_tokens_text'] = df_gold['right_tokens_text'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "df_gold.tail()\n",
    "\n",
    "# Start the rest of the data after the point where the labeled data starts\n",
    "df_in = df_out.iloc[df_gold.index[-1] + 1:, :]\n",
    "df_in.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Split Data into Train / Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    df_in_fixed, \n",
    "    df_in_fixed['label'].values, \n",
    "    test_size=0.3,\n",
    "    random_state=1337,\n",
    ")\n",
    "\n",
    "len(df_train.index), len(df_test.index), y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Split Data into Train / Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for PySpark\n",
    "df_train, df_test = entity_df.randomSplit([0.7, 0.3], seed=1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Labels for Language Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup our spaCy Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jsonlines, sys\n",
    "from snorkel.labeling import labeling_function, LabelingFunction\n",
    "from snorkel.preprocess import preprocessor\n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "spacy = SpacyPreprocessor(\n",
    "    text_field='body',\n",
    "    doc_field='spacy',\n",
    "    memoize=True,\n",
    "    language='en_core_web_lg',\n",
    "    disable=['vectors'],\n",
    ")\n",
    "\n",
    "@preprocessor(memoize=True, pre=[spacy])\n",
    "def restore_entity(x):\n",
    "    \n",
    "    entity = None\n",
    "    for ent in x['spacy'].ents:\n",
    "        if  ent.start == row['entity_start'] \\\n",
    "        and ent.end   == row['entity_end']:\n",
    "            entity = ent\n",
    "\n",
    "    if entity is None:\n",
    "        raise Exception('Missing entity!')\n",
    "\n",
    "    x['entity'] = entity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts_rx = re.compile('^\\W')\n",
    "          \n",
    "@labeling_function()\n",
    "def lf_starts_with_char(x):\n",
    "    \"\"\"NEGATIVE if starts with a non-alpha-numeric value\"\"\"\n",
    "    return NEGATIVE if starts_rx.match(x['entity_text']) else ABSTAIN\n",
    "\n",
    "\n",
    "number_end_rx = re.compile('^[a-zA-Z]+[0-9\\W]+$')\n",
    "\n",
    "@labeling_function()\n",
    "def lf_ends_with_symbol_or_number(x):\n",
    "    \"\"\"POSITIVE if starts with letter and ends in number\"\"\"\n",
    "    return POSITIVE if number_end_rx.match(x['entity_text']) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_wrong_entity_type(x):\n",
    "    return NEGATIVE if x['ent_type'] in ['PERSON', 'NORP', 'FAC', 'GPE', 'LOC', \n",
    "                                         'LAW', 'DATE', 'TIME', 'PERCENT',\n",
    "                                         'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL',] else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_token_count_2(x):\n",
    "    \"\"\"NEGATIVE if entity has more than 2 words in it\"\"\"\n",
    "    return NEGATIVE if len(x['entity_text'].split(' ')) > 2 else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_token_count_1(x):\n",
    "    \"\"\"NEGATIVE if entity has more than 1 word in it\"\"\"\n",
    "    return NEGATIVE if len(x['entity_text'].split(' ')) > 1 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'POS': 'VERB'}, {'POS': 'ADP'}, {'POS': 'PROPN'}]\n",
    "matcher.add(\"VERB_ADP_PROPN\", None, pattern)\n",
    "\n",
    "@labeling_function(pre=[spacy, restore_entity])\n",
    "def lf_verb_in_noun(x):\n",
    "    \"\"\"Return positive if the pattern\"\"\"\n",
    "    sp = x['spacy']\n",
    "    matches = matcher(sp)\n",
    "    \n",
    "    found = False\n",
    "    for match_id, start, end in matches:\n",
    "        if end == x['entity_end']:\n",
    "            pass\n",
    "        if start == x['start'] - 2:            \n",
    "            if sp[start].text in ['work', 'written', 'wrote']:                \n",
    "                if sp[start + 1].text in ['in']:\n",
    "                    return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
