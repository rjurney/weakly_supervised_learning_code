{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Transfer Learning\n",
    "\n",
    "In this chapter we'll be exploring *transfer learning*, where a model trained for one purpose is used for another. We'll take our initial model and enhance it using text and source code embeddings.\n",
    "\n",
    "Since we have already explained the workings of this model in the previous chapter, the comments for the model basics have been removed. See [Chapter 2 (add link)]() and [Weakly Supervised Learning - Stack Overflow Tag Labeler.ipynb](../ch02/Weakly%20Supervised%20Learning%20-%20Stack%20Overflow%20Tag%20Labeler.ipynb) to learn more about the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rjurney/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rjurney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import lib.utils\n",
    "\n",
    "# Disable all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 or more GPUs is available: True\n",
      "GPUs on tap: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")\n",
    "print(f'1 or more GPUs is available: {gpu_avail}')\n",
    "\n",
    "avail_gpus = tf.compat.v2.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs on tap: {avail_gpus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_WIDTH = 50\n",
    "pd.set_option('display.max_colwidth', COLUMN_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 128\n",
    "MAX_LEN     = 200\n",
    "TOKEN_COUNT = 10000\n",
    "EMBED_SIZE  = 300\n",
    "TEST_SPLIT  = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Body</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>...</th>\n",
       "      <th>label_776</th>\n",
       "      <th>label_777</th>\n",
       "      <th>label_778</th>\n",
       "      <th>label_779</th>\n",
       "      <th>label_780</th>\n",
       "      <th>label_781</th>\n",
       "      <th>label_782</th>\n",
       "      <th>label_783</th>\n",
       "      <th>label_784</th>\n",
       "      <th>label_785</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[How, animate, Flutter, layout, keyboard, appe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Creating, Carousel, using, FutureBuilder, I, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               _Body  label_0  label_1  \\\n",
       "0  [How, animate, Flutter, layout, keyboard, appe...        0        0   \n",
       "1  [Creating, Carousel, using, FutureBuilder, I, ...        0        0   \n",
       "\n",
       "   label_2  label_3  label_4  label_5  label_6  label_7  label_8  ...  \\\n",
       "0        0        0        0        0        0        0        0  ...   \n",
       "1        0        0        0        0        0        0        0  ...   \n",
       "\n",
       "   label_776  label_777  label_778  label_779  label_780  label_781  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "\n",
       "   label_782  label_783  label_784  label_785  \n",
       "0          0          0          0          0  \n",
       "1          0          0          0          0  \n",
       "\n",
       "[2 rows x 787 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag limit defines which dataset to load - those with tags having at least 50K, 20K, 10K, 5K or 2K instances\n",
    "TAG_LIMIT = 2000\n",
    "\n",
    "# Pre-computed sorted list of tag/index pairs\n",
    "sorted_all_tags = json.load(open(f'../data/stackoverflow/sorted_all_tags.{TAG_LIMIT}.json'))\n",
    "max_index = sorted_all_tags[-1][0] + 1\n",
    "\n",
    "# Load the parquet file using pyarrow for this tag limit, using the sorted tag index to specify the columns\n",
    "posts_df = pd.read_parquet(\n",
    "    f'../data/stackoverflow/Questions.Stratified.Final.{TAG_LIMIT}.parquet',\n",
    "    columns=['_Body'] + ['label_{}'.format(i) for i in range(0, max_index)],\n",
    "    engine='pyarrow'\n",
    ")\n",
    "posts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,554,788 Stack Overflow questions with a tag having at least 2,000 occurrences\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    '{:,} Stack Overflow questions with a tag having at least 2,000 occurrences'.format(\n",
    "        len(posts_df.index)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero rows: 1,554,788, Total rows: 1,554,788, Non-zero ratio: 1.0, Least tags: 1, Most tags: 6\n"
     ]
    }
   ],
   "source": [
    "test_matrix = posts_df[[f'label_{i}' for i in range(0, max_index)]].as_matrix()\n",
    "\n",
    "tests = np.count_nonzero(test_matrix.sum(axis=1)), \\\n",
    "        test_matrix.sum(axis=1).shape[0], \\\n",
    "        test_matrix.sum(axis=1).min(), \\\n",
    "        test_matrix.sum(axis=1).max()\n",
    "\n",
    "print(f'Non-zero rows: {tests[0]:,}, Total rows: {tests[1]:,}, Non-zero ratio: {tests[0]/tests[1]:,}, Least tags: {tests[2]:,}, Most tags: {tests[3]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_index = json.load(open(f'../data/stackoverflow/tag_index.{TAG_LIMIT}.json'))\n",
    "index_tag = json.load(open(f'../data/stackoverflow/index_tag.{TAG_LIMIT}.json'))\n",
    "\n",
    "# Sanity check the different files\n",
    "assert( len(tag_index.keys()) == len(index_tag.keys()) == len(sorted_all_tags) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Factor: 60 Training Count: 1,536,000\n"
     ]
    }
   ],
   "source": [
    "# Convert label columns to numpy array\n",
    "labels = posts_df[list(posts_df.columns)[1:]].to_numpy()\n",
    "\n",
    "# Training_count must be a multiple of the BATCH_SIZE times the MAX_LEN for the Elmo embedding layer\n",
    "highest_factor = math.floor(len(posts_df.index) / (BATCH_SIZE * MAX_LEN))\n",
    "training_count = highest_factor * BATCH_SIZE * MAX_LEN\n",
    "print('Highest Factor: {:,} Training Count: {:,}'.format(highest_factor, training_count))\n",
    "\n",
    "documents = []\n",
    "for body in posts_df[0:training_count]['_Body'].values.tolist():\n",
    "    words = body.tolist()\n",
    "    documents.append(' '.join(words))\n",
    "\n",
    "labels = labels[0:training_count]\n",
    "\n",
    "# Conserve RAM\n",
    "del posts_df\n",
    "gc.collect()\n",
    "\n",
    "# Lengths for x and y match\n",
    "assert( len(documents) == training_count == labels.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536000, 200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=TOKEN_COUNT + 1,\n",
    "    oov_token='__PAD__'\n",
    ")\n",
    "tokenizer.fit_on_texts(documents)\n",
    "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= TOKEN_COUNT}\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(documents)\n",
    "\n",
    "padded_sequences = pad_sequences(\n",
    "    sequences,\n",
    "    maxlen=MAX_LEN,\n",
    "    dtype='int32',\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    value=0,\n",
    ")\n",
    "tokenizer.sequences_to_matrix(padded_sequences, mode='tfidf')\n",
    "\n",
    "# Conserve RAM\n",
    "del documents\n",
    "del sequences\n",
    "gc.collect()\n",
    "\n",
    "# Verify that all padded documents are now the same length\n",
    "assert( min([len(x) for x in padded_sequences]) == MAX_LEN == max([len(x) for x in padded_sequences]) )\n",
    "\n",
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe Embeddings\n",
    "\n",
    "Stanford defines [GloVe Embeddings](https://nlp.stanford.edu/projects/glove/) as:\n",
    "\n",
    "> GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\n",
    "\n",
    "We'll try them out to see if they can beat our own embedding, specific to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open('../data/GloVe/glove.6B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 300),\n",
       " {'__PAD__': 1,\n",
       "  'pad': 2,\n",
       "  'i': 3,\n",
       "  'using': 4,\n",
       "  'like': 5,\n",
       "  'code': 6,\n",
       "  'the': 7,\n",
       "  'get': 8,\n",
       "  'use': 9,\n",
       "  'how': 10,\n",
       "  'file': 11,\n",
       "  'want': 12,\n",
       "  'would': 13,\n",
       "  'way': 14,\n",
       "  'error': 15,\n",
       "  'one': 16,\n",
       "  'data': 17,\n",
       "  'is': 18,\n",
       "  '1': 19,\n",
       "  'need': 20,\n",
       "  '2': 21,\n",
       "  'following': 22,\n",
       "  'problem': 23,\n",
       "  'trying': 24,\n",
       "  'this': 25,\n",
       "  'app': 26,\n",
       "  'work': 27,\n",
       "  'know': 28,\n",
       "  'user': 29,\n",
       "  'function': 30,\n",
       "  'c': 31,\n",
       "  'class': 32,\n",
       "  'what': 33,\n",
       "  'but': 34,\n",
       "  'tried': 35,\n",
       "  'application': 36,\n",
       "  'example': 37,\n",
       "  'so': 38,\n",
       "  'also': 39,\n",
       "  'method': 40,\n",
       "  'time': 41,\n",
       "  'set': 42,\n",
       "  'new': 43,\n",
       "  'server': 44,\n",
       "  '0': 45,\n",
       "  'in': 46,\n",
       "  'something': 47,\n",
       "  'run': 48,\n",
       "  'thanks': 49,\n",
       "  'if': 50,\n",
       "  'value': 51,\n",
       "  'make': 52,\n",
       "  'my': 53,\n",
       "  'it': 54,\n",
       "  'help': 55,\n",
       "  'create': 56,\n",
       "  'works': 57,\n",
       "  'project': 58,\n",
       "  '3': 59,\n",
       "  'first': 60,\n",
       "  'could': 61,\n",
       "  'however': 62,\n",
       "  'page': 63,\n",
       "  'working': 64,\n",
       "  'find': 65,\n",
       "  'see': 66,\n",
       "  'object': 67,\n",
       "  'list': 68,\n",
       "  'files': 69,\n",
       "  'question': 70,\n",
       "  'two': 71,\n",
       "  'when': 72,\n",
       "  'java': 73,\n",
       "  'type': 74,\n",
       "  'here': 75,\n",
       "  'add': 76,\n",
       "  'possible': 77,\n",
       "  'table': 78,\n",
       "  'different': 79,\n",
       "  'view': 80,\n",
       "  'test': 81,\n",
       "  'used': 82,\n",
       "  'string': 83,\n",
       "  'without': 84,\n",
       "  'line': 85,\n",
       "  'call': 86,\n",
       "  '4': 87,\n",
       "  'web': 88,\n",
       "  'change': 89,\n",
       "  'any': 90,\n",
       "  'seems': 91,\n",
       "  'database': 92,\n",
       "  'able': 93,\n",
       "  'and': 94,\n",
       "  'text': 95,\n",
       "  'found': 96,\n",
       "  'image': 97,\n",
       "  'another': 98,\n",
       "  'for': 99,\n",
       "  'running': 100,\n",
       "  'android': 101,\n",
       "  'solution': 102,\n",
       "  'name': 103,\n",
       "  'fine': 104,\n",
       "  'output': 105,\n",
       "  'getting': 106,\n",
       "  'net': 107,\n",
       "  'update': 108,\n",
       "  'values': 109,\n",
       "  'array': 110,\n",
       "  'version': 111,\n",
       "  '5': 112,\n",
       "  'edit': 113,\n",
       "  'windows': 114,\n",
       "  'try': 115,\n",
       "  'still': 116,\n",
       "  'issue': 117,\n",
       "  'access': 118,\n",
       "  'anyone': 119,\n",
       "  'number': 120,\n",
       "  'api': 121,\n",
       "  'simple': 122,\n",
       "  'python': 123,\n",
       "  'build': 124,\n",
       "  'can': 125,\n",
       "  'right': 126,\n",
       "  'even': 127,\n",
       "  'query': 128,\n",
       "  'php': 129,\n",
       "  'read': 130,\n",
       "  'case': 131,\n",
       "  'script': 132,\n",
       "  'please': 133,\n",
       "  'e': 134,\n",
       "  'command': 135,\n",
       "  'created': 136,\n",
       "  'wrong': 137,\n",
       "  'html': 138,\n",
       "  'form': 139,\n",
       "  'button': 140,\n",
       "  'service': 141,\n",
       "  'system': 142,\n",
       "  'instead': 143,\n",
       "  'sure': 144,\n",
       "  'request': 145,\n",
       "  'google': 146,\n",
       "  'result': 147,\n",
       "  'multiple': 148,\n",
       "  'model': 149,\n",
       "  'write': 150,\n",
       "  'inside': 151,\n",
       "  'now': 152,\n",
       "  'a': 153,\n",
       "  'program': 154,\n",
       "  'every': 155,\n",
       "  'since': 156,\n",
       "  'sql': 157,\n",
       "  'js': 158,\n",
       "  'cannot': 159,\n",
       "  'return': 160,\n",
       "  'called': 161,\n",
       "  'think': 162,\n",
       "  'variable': 163,\n",
       "  'many': 164,\n",
       "  'custom': 165,\n",
       "  'id': 166,\n",
       "  'really': 167,\n",
       "  'url': 168,\n",
       "  'library': 169,\n",
       "  'message': 170,\n",
       "  'xml': 171,\n",
       "  'client': 172,\n",
       "  'column': 173,\n",
       "  'looks': 174,\n",
       "  'why': 175,\n",
       "  'got': 176,\n",
       "  'understand': 177,\n",
       "  'based': 178,\n",
       "  'process': 179,\n",
       "  'controller': 180,\n",
       "  'well': 181,\n",
       "  'key': 182,\n",
       "  'show': 183,\n",
       "  'input': 184,\n",
       "  'best': 185,\n",
       "  'check': 186,\n",
       "  'memory': 187,\n",
       "  'back': 188,\n",
       "  'looking': 189,\n",
       "  'order': 190,\n",
       "  'go': 191,\n",
       "  '7': 192,\n",
       "  '8': 193,\n",
       "  'default': 194,\n",
       "  'correct': 195,\n",
       "  'point': 196,\n",
       "  'idea': 197,\n",
       "  'second': 198,\n",
       "  'etc': 199,\n",
       "  'javascript': 200,\n",
       "  'within': 201,\n",
       "  'start': 202,\n",
       "  'currently': 203,\n",
       "  'already': 204,\n",
       "  'exception': 205,\n",
       "  'seem': 206,\n",
       "  'via': 207,\n",
       "  'event': 208,\n",
       "  'as': 209,\n",
       "  'json': 210,\n",
       "  'field': 211,\n",
       "  'load': 212,\n",
       "  'added': 213,\n",
       "  'much': 214,\n",
       "  'x': 215,\n",
       "  'source': 216,\n",
       "  'property': 217,\n",
       "  'main': 218,\n",
       "  'specific': 219,\n",
       "  'bit': 220,\n",
       "  'post': 221,\n",
       "  'good': 222,\n",
       "  'done': 223,\n",
       "  'objects': 224,\n",
       "  'better': 225,\n",
       "  '10': 226,\n",
       "  'part': 227,\n",
       "  '6': 228,\n",
       "  'current': 229,\n",
       "  'say': 230,\n",
       "  'open': 231,\n",
       "  'size': 232,\n",
       "  'element': 233,\n",
       "  'does': 234,\n",
       "  'link': 235,\n",
       "  'folder': 236,\n",
       "  'content': 237,\n",
       "  'directory': 238,\n",
       "  'single': 239,\n",
       "  'results': 240,\n",
       "  'users': 241,\n",
       "  'click': 242,\n",
       "  'studio': 243,\n",
       "  'information': 244,\n",
       "  'returns': 245,\n",
       "  'instance': 246,\n",
       "  'always': 247,\n",
       "  'far': 248,\n",
       "  'put': 249,\n",
       "  'end': 250,\n",
       "  'date': 251,\n",
       "  'display': 252,\n",
       "  'jquery': 253,\n",
       "  'everything': 254,\n",
       "  'path': 255,\n",
       "  'methods': 256,\n",
       "  'similar': 257,\n",
       "  'thread': 258,\n",
       "  'loop': 259,\n",
       "  'framework': 260,\n",
       "  'around': 261,\n",
       "  'given': 262,\n",
       "  'look': 263,\n",
       "  'search': 264,\n",
       "  'visual': 265,\n",
       "  'anything': 266,\n",
       "  'browser': 267,\n",
       "  'select': 268,\n",
       "  'answer': 269,\n",
       "  'row': 270,\n",
       "  'functions': 271,\n",
       "  'missing': 272,\n",
       "  'store': 273,\n",
       "  'reference': 274,\n",
       "  'someone': 275,\n",
       "  'may': 276,\n",
       "  'advance': 277,\n",
       "  'appreciated': 278,\n",
       "  'pass': 279,\n",
       "  'creating': 280,\n",
       "  'g': 281,\n",
       "  'site': 282,\n",
       "  'node': 283,\n",
       "  'implement': 284,\n",
       "  'contains': 285,\n",
       "  'let': 286,\n",
       "  'control': 287,\n",
       "  'classes': 288,\n",
       "  'module': 289,\n",
       "  'ios': 290,\n",
       "  'thing': 291,\n",
       "  'there': 292,\n",
       "  'package': 293,\n",
       "  'send': 294,\n",
       "  'errors': 295,\n",
       "  'we': 296,\n",
       "  'actually': 297,\n",
       "  'log': 298,\n",
       "  'index': 299,\n",
       "  'uses': 300,\n",
       "  'last': 301,\n",
       "  'asp': 302,\n",
       "  'b': 303,\n",
       "  'changes': 304,\n",
       "  'going': 305,\n",
       "  'lot': 306,\n",
       "  'local': 307,\n",
       "  'to': 308,\n",
       "  'format': 309,\n",
       "  'install': 310,\n",
       "  'option': 311,\n",
       "  'remove': 312,\n",
       "  'or': 313,\n",
       "  'item': 314,\n",
       "  'map': 315,\n",
       "  'adding': 316,\n",
       "  'must': 317,\n",
       "  'either': 318,\n",
       "  'screen': 319,\n",
       "  'installed': 320,\n",
       "  'figure': 321,\n",
       "  'things': 322,\n",
       "  'correctly': 323,\n",
       "  'elements': 324,\n",
       "  'parameter': 325,\n",
       "  'might': 326,\n",
       "  'take': 327,\n",
       "  'window': 328,\n",
       "  'convert': 329,\n",
       "  'images': 330,\n",
       "  'template': 331,\n",
       "  'css': 332,\n",
       "  'background': 333,\n",
       "  'com': 334,\n",
       "  'ideas': 335,\n",
       "  'give': 336,\n",
       "  'note': 337,\n",
       "  'console': 338,\n",
       "  'connection': 339,\n",
       "  'setting': 340,\n",
       "  'made': 341,\n",
       "  'defined': 342,\n",
       "  'keep': 343,\n",
       "  'compile': 344,\n",
       "  'shows': 345,\n",
       "  'rows': 346,\n",
       "  'response': 347,\n",
       "  'nothing': 348,\n",
       "  'thank': 349,\n",
       "  'spring': 350,\n",
       "  'expected': 351,\n",
       "  'fix': 352,\n",
       "  'null': 353,\n",
       "  'save': 354,\n",
       "  'gets': 355,\n",
       "  'documentation': 356,\n",
       "  'plugin': 357,\n",
       "  'config': 358,\n",
       "  'columns': 359,\n",
       "  'properties': 360,\n",
       "  'structure': 361,\n",
       "  'reason': 362,\n",
       "  'side': 363,\n",
       "  'after': 364,\n",
       "  'items': 365,\n",
       "  'header': 366,\n",
       "  'long': 367,\n",
       "  'task': 368,\n",
       "  'next': 369,\n",
       "  'variables': 370,\n",
       "  'though': 371,\n",
       "  'difference': 372,\n",
       "  'approach': 373,\n",
       "  'writing': 374,\n",
       "  'gives': 375,\n",
       "  'tests': 376,\n",
       "  'non': 377,\n",
       "  'website': 378,\n",
       "  'login': 379,\n",
       "  'action': 380,\n",
       "  'support': 381,\n",
       "  'chrome': 382,\n",
       "  'then': 383,\n",
       "  'lines': 384,\n",
       "  'configuration': 385,\n",
       "  'available': 386,\n",
       "  'several': 387,\n",
       "  'fields': 388,\n",
       "  'tell': 389,\n",
       "  'handle': 390,\n",
       "  'include': 391,\n",
       "  'parameters': 392,\n",
       "  'static': 393,\n",
       "  'maybe': 394,\n",
       "  'times': 395,\n",
       "  'interface': 396,\n",
       "  'stored': 397,\n",
       "  'mvc': 398,\n",
       "  'entity': 399,\n",
       "  'machine': 400,\n",
       "  'device': 401,\n",
       "  'calls': 402,\n",
       "  'mysql': 403,\n",
       "  'changed': 404,\n",
       "  'needs': 405,\n",
       "  'component': 406,\n",
       "  'testing': 407,\n",
       "  'statement': 408,\n",
       "  'achieve': 409,\n",
       "  'solve': 410,\n",
       "  'top': 411,\n",
       "  'empty': 412,\n",
       "  'else': 413,\n",
       "  'implementation': 414,\n",
       "  'generate': 415,\n",
       "  'types': 416,\n",
       "  'state': 417,\n",
       "  'thought': 418,\n",
       "  'http': 419,\n",
       "  'copy': 420,\n",
       "  'calling': 421,\n",
       "  'questions': 422,\n",
       "  'ui': 423,\n",
       "  'db': 424,\n",
       "  'setup': 425,\n",
       "  'standard': 426,\n",
       "  'session': 427,\n",
       "  'vs': 428,\n",
       "  'wondering': 429,\n",
       "  'rails': 430,\n",
       "  'problems': 431,\n",
       "  'generated': 432,\n",
       "  'simply': 433,\n",
       "  'compiler': 434,\n",
       "  'rather': 435,\n",
       "  'tables': 436,\n",
       "  'address': 437,\n",
       "  'all': 438,\n",
       "  'linux': 439,\n",
       "  'allow': 440,\n",
       "  'attribute': 441,\n",
       "  'core': 442,\n",
       "  'basically': 443,\n",
       "  'reading': 444,\n",
       "  'django': 445,\n",
       "  'written': 446,\n",
       "  'print': 447,\n",
       "  'stack': 448,\n",
       "  'large': 449,\n",
       "  'box': 450,\n",
       "  'never': 451,\n",
       "  'execute': 452,\n",
       "  'kind': 453,\n",
       "  'eclipse': 454,\n",
       "  'debug': 455,\n",
       "  'fails': 456,\n",
       "  'insert': 457,\n",
       "  'document': 458,\n",
       "  'on': 459,\n",
       "  'properly': 460,\n",
       "  'environment': 461,\n",
       "  'mean': 462,\n",
       "  'level': 463,\n",
       "  'mode': 464,\n",
       "  'color': 465,\n",
       "  'delete': 466,\n",
       "  'tag': 467,\n",
       "  'takes': 468,\n",
       "  'password': 469,\n",
       "  'happens': 470,\n",
       "  'making': 471,\n",
       "  'sort': 472,\n",
       "  'bar': 473,\n",
       "  'collection': 474,\n",
       "  'full': 475,\n",
       "  'certain': 476,\n",
       "  'says': 477,\n",
       "  'location': 478,\n",
       "  'performance': 479,\n",
       "  'language': 480,\n",
       "  'related': 481,\n",
       "  'rest': 482,\n",
       "  'layout': 483,\n",
       "  'follows': 484,\n",
       "  'domain': 485,\n",
       "  'place': 486,\n",
       "  'r': 487,\n",
       "  'sample': 488,\n",
       "  'do': 489,\n",
       "  'automatically': 490,\n",
       "  'quite': 491,\n",
       "  'options': 492,\n",
       "  'parent': 493,\n",
       "  'context': 494,\n",
       "  'connect': 495,\n",
       "  'directly': 496,\n",
       "  'video': 497,\n",
       "  'whether': 498,\n",
       "  'runs': 499,\n",
       "  'filter': 500,\n",
       "  'true': 501,\n",
       "  'left': 502,\n",
       "  'menu': 503,\n",
       "  'numbers': 504,\n",
       "  'whole': 505,\n",
       "  'makes': 506,\n",
       "  'that': 507,\n",
       "  'n': 508,\n",
       "  'activity': 509,\n",
       "  'per': 510,\n",
       "  'group': 511,\n",
       "  'exactly': 512,\n",
       "  'started': 513,\n",
       "  'manually': 514,\n",
       "  'dll': 515,\n",
       "  'settings': 516,\n",
       "  'pattern': 517,\n",
       "  'play': 518,\n",
       "  'ok': 519,\n",
       "  'upload': 520,\n",
       "  'behavior': 521,\n",
       "  'child': 522,\n",
       "  'separate': 523,\n",
       "  'failed': 524,\n",
       "  'characters': 525,\n",
       "  'suggestions': 526,\n",
       "  'little': 527,\n",
       "  'not': 528,\n",
       "  'appears': 529,\n",
       "  'existing': 530,\n",
       "  'avoid': 531,\n",
       "  'basic': 532,\n",
       "  'strings': 533,\n",
       "  'download': 534,\n",
       "  'container': 535,\n",
       "  'tab': 536,\n",
       "  'pages': 537,\n",
       "  '9': 538,\n",
       "  'seen': 539,\n",
       "  'pretty': 540,\n",
       "  'small': 541,\n",
       "  'provide': 542,\n",
       "  'email': 543,\n",
       "  'ajax': 544,\n",
       "  'issues': 545,\n",
       "  'original': 546,\n",
       "  'requests': 547,\n",
       "  'means': 548,\n",
       "  'selected': 549,\n",
       "  'import': 550,\n",
       "  'syntax': 551,\n",
       "  'block': 552,\n",
       "  'names': 553,\n",
       "  'yet': 554,\n",
       "  'repository': 555,\n",
       "  'updated': 556,\n",
       "  'changing': 557,\n",
       "  'unit': 558,\n",
       "  'come': 559,\n",
       "  'match': 560,\n",
       "  'easy': 561,\n",
       "  'xcode': 562,\n",
       "  'projects': 563,\n",
       "  'replace': 564,\n",
       "  'particular': 565,\n",
       "  'examples': 566,\n",
       "  'constructor': 567,\n",
       "  'space': 568,\n",
       "  'info': 569,\n",
       "  'cell': 570,\n",
       "  'built': 571,\n",
       "  'actual': 572,\n",
       "  'unable': 573,\n",
       "  'shown': 574,\n",
       "  'required': 575,\n",
       "  'jar': 576,\n",
       "  'root': 577,\n",
       "  'explain': 578,\n",
       "  'events': 579,\n",
       "  'move': 580,\n",
       "  'worked': 581,\n",
       "  'old': 582,\n",
       "  'no': 583,\n",
       "  'three': 584,\n",
       "  'git': 585,\n",
       "  'define': 586,\n",
       "  'loaded': 587,\n",
       "  'step': 588,\n",
       "  'count': 589,\n",
       "  'messages': 590,\n",
       "  'great': 591,\n",
       "  'real': 592,\n",
       "  'building': 593,\n",
       "  'loading': 594,\n",
       "  'authentication': 595,\n",
       "  'base': 596,\n",
       "  'network': 597,\n",
       "  'account': 598,\n",
       "  'character': 599,\n",
       "  'views': 600,\n",
       "  'iphone': 601,\n",
       "  'clear': 602,\n",
       "  'development': 603,\n",
       "  'points': 604,\n",
       "  'token': 605,\n",
       "  'position': 606,\n",
       "  'argument': 607,\n",
       "  'dynamic': 608,\n",
       "  'checked': 609,\n",
       "  'common': 610,\n",
       "  'ie': 611,\n",
       "  'libraries': 612,\n",
       "  'extension': 613,\n",
       "  'os': 614,\n",
       "  'returned': 615,\n",
       "  'design': 616,\n",
       "  'angular': 617,\n",
       "  'firefox': 618,\n",
       "  'apache': 619,\n",
       "  'from': 620,\n",
       "  'which': 621,\n",
       "  'style': 622,\n",
       "  'cache': 623,\n",
       "  'security': 624,\n",
       "  'native': 625,\n",
       "  'stream': 626,\n",
       "  'record': 627,\n",
       "  'successfully': 628,\n",
       "  'width': 629,\n",
       "  'word': 630,\n",
       "  'showing': 631,\n",
       "  'with': 632,\n",
       "  'facebook': 633,\n",
       "  'resource': 634,\n",
       "  'parse': 635,\n",
       "  'exist': 636,\n",
       "  'where': 637,\n",
       "  'records': 638,\n",
       "  'services': 639,\n",
       "  'contain': 640,\n",
       "  'course': 641,\n",
       "  'redirect': 642,\n",
       "  'needed': 643,\n",
       "  'according': 644,\n",
       "  'except': 645,\n",
       "  'ruby': 646,\n",
       "  'mobile': 647,\n",
       "  'are': 648,\n",
       "  'target': 649,\n",
       "  'threads': 650,\n",
       "  'enough': 651,\n",
       "  'least': 652,\n",
       "  'feature': 653,\n",
       "  'expression': 654,\n",
       "  '11': 655,\n",
       "  'comes': 656,\n",
       "  'previous': 657,\n",
       "  'nested': 658,\n",
       "  'validation': 659,\n",
       "  'guess': 660,\n",
       "  'appear': 661,\n",
       "  '100': 662,\n",
       "  'sdk': 663,\n",
       "  'job': 664,\n",
       "  'dialog': 665,\n",
       "  'scroll': 666,\n",
       "  'pointer': 667,\n",
       "  'across': 668,\n",
       "  'height': 669,\n",
       "  'int': 670,\n",
       "  'people': 671,\n",
       "  'apps': 672,\n",
       "  'probably': 673,\n",
       "  'close': 674,\n",
       "  'at': 675,\n",
       "  'product': 676,\n",
       "  'vector': 677,\n",
       "  'valid': 678,\n",
       "  'functionality': 679,\n",
       "  'tree': 680,\n",
       "  'maven': 681,\n",
       "  'sometimes': 682,\n",
       "  'seconds': 683,\n",
       "  'div': 684,\n",
       "  'wanted': 685,\n",
       "  'binary': 686,\n",
       "  'displayed': 687,\n",
       "  'external': 688,\n",
       "  'runtime': 689,\n",
       "  'stop': 690,\n",
       "  'bug': 691,\n",
       "  'dependencies': 692,\n",
       "  'implemented': 693,\n",
       "  'you': 694,\n",
       "  'warning': 695,\n",
       "  'arguments': 696,\n",
       "  'complete': 697,\n",
       "  'programming': 698,\n",
       "  'dynamically': 699,\n",
       "  'goes': 700,\n",
       "  'keys': 701,\n",
       "  'random': 702,\n",
       "  'section': 703,\n",
       "  'perform': 704,\n",
       "  'frame': 705,\n",
       "  'microsoft': 706,\n",
       "  'passed': 707,\n",
       "  'integer': 708,\n",
       "  'normal': 709,\n",
       "  'specify': 710,\n",
       "  'tool': 711,\n",
       "  'route': 712,\n",
       "  'remote': 713,\n",
       "  'somehow': 714,\n",
       "  'cause': 715,\n",
       "  'due': 716,\n",
       "  'apply': 717,\n",
       "  'solutions': 718,\n",
       "  'containing': 719,\n",
       "  'links': 720,\n",
       "  'less': 721,\n",
       "  'none': 722,\n",
       "  'bad': 723,\n",
       "  'status': 724,\n",
       "  'cases': 725,\n",
       "  'matrix': 726,\n",
       "  'passing': 727,\n",
       "  'modules': 728,\n",
       "  'algorithm': 729,\n",
       "  'docker': 730,\n",
       "  'receive': 731,\n",
       "  'am': 732,\n",
       "  'phone': 733,\n",
       "  'unfortunately': 734,\n",
       "  'trouble': 735,\n",
       "  'versions': 736,\n",
       "  'binding': 737,\n",
       "  'public': 738,\n",
       "  'details': 739,\n",
       "  'resources': 740,\n",
       "  'later': 741,\n",
       "  'thinking': 742,\n",
       "  'should': 743,\n",
       "  'ways': 744,\n",
       "  'react': 745,\n",
       "  'words': 746,\n",
       "  'exists': 747,\n",
       "  'starting': 748,\n",
       "  'tools': 749,\n",
       "  'socket': 750,\n",
       "  'pdf': 751,\n",
       "  'port': 752,\n",
       "  'big': 753,\n",
       "  'models': 754,\n",
       "  'entire': 755,\n",
       "  'applications': 756,\n",
       "  'logic': 757,\n",
       "  'operation': 758,\n",
       "  'looked': 759,\n",
       "  'answers': 760,\n",
       "  'title': 761,\n",
       "  'admin': 762,\n",
       "  'mac': 763,\n",
       "  'dependency': 764,\n",
       "  'queries': 765,\n",
       "  'assume': 766,\n",
       "  'graph': 767,\n",
       "  'swift': 768,\n",
       "  'generic': 769,\n",
       "  'switch': 770,\n",
       "  'length': 771,\n",
       "  'happening': 772,\n",
       "  'understanding': 773,\n",
       "  'day': 774,\n",
       "  'retrieve': 775,\n",
       "  'csv': 776,\n",
       "  'game': 777,\n",
       "  'named': 778,\n",
       "  'buttons': 779,\n",
       "  'laravel': 780,\n",
       "  'excel': 781,\n",
       "  'obviously': 782,\n",
       "  'grid': 783,\n",
       "  'tags': 784,\n",
       "  'unique': 785,\n",
       "  'host': 786,\n",
       "  'range': 787,\n",
       "  'release': 788,\n",
       "  '64': 789,\n",
       "  'require': 790,\n",
       "  'specified': 791,\n",
       "  'developing': 792,\n",
       "  'global': 793,\n",
       "  'p': 794,\n",
       "  'assembly': 795,\n",
       "  'shared': 796,\n",
       "  'happen': 797,\n",
       "  'modify': 798,\n",
       "  'stuff': 799,\n",
       "  'including': 800,\n",
       "  'hard': 801,\n",
       "  'drop': 802,\n",
       "  'additional': 803,\n",
       "  'auto': 804,\n",
       "  'operator': 805,\n",
       "  '12': 806,\n",
       "  'returning': 807,\n",
       "  'false': 808,\n",
       "  'tutorial': 809,\n",
       "  'duplicate': 810,\n",
       "  'sent': 811,\n",
       "  'forms': 812,\n",
       "  'contents': 813,\n",
       "  'queue': 814,\n",
       "  'expect': 815,\n",
       "  'org': 816,\n",
       "  'enter': 817,\n",
       "  'situation': 818,\n",
       "  'completely': 819,\n",
       "  'exe': 820,\n",
       "  'home': 821,\n",
       "  'anybody': 822,\n",
       "  'packages': 823,\n",
       "  'push': 824,\n",
       "  'attributes': 825,\n",
       "  'layer': 826,\n",
       "  'trigger': 827,\n",
       "  'various': 828,\n",
       "  'executed': 829,\n",
       "  'shell': 830,\n",
       "  'prevent': 831,\n",
       "  'gcc': 832,\n",
       "  'bottom': 833,\n",
       "  'scala': 834,\n",
       "  'gradle': 835,\n",
       "  'double': 836,\n",
       "  'procedure': 837,\n",
       "  'handler': 838,\n",
       "  'requires': 839,\n",
       "  'schema': 840,\n",
       "  'fact': 841,\n",
       "  'certificate': 842,\n",
       "  'effect': 843,\n",
       "  'nodes': 844,\n",
       "  'included': 845,\n",
       "  'lib': 846,\n",
       "  'fixed': 847,\n",
       "  'report': 848,\n",
       "  '20': 849,\n",
       "  'resolve': 850,\n",
       "  'sub': 851,\n",
       "  'lists': 852,\n",
       "  'proxy': 853,\n",
       "  'processing': 854,\n",
       "  'internet': 855,\n",
       "  'wpf': 856,\n",
       "  'execution': 857,\n",
       "  'outside': 858,\n",
       "  'together': 859,\n",
       "  'supposed': 860,\n",
       "  'scope': 861,\n",
       "  'invalid': 862,\n",
       "  'commands': 863,\n",
       "  'im': 864,\n",
       "  'recently': 865,\n",
       "  'ask': 866,\n",
       "  'private': 867,\n",
       "  'icon': 868,\n",
       "  'render': 869,\n",
       "  'stuck': 870,\n",
       "  'references': 871,\n",
       "  'sense': 872,\n",
       "  'bootstrap': 873,\n",
       "  'oracle': 874,\n",
       "  'provided': 875,\n",
       "  'latest': 876,\n",
       "  'py': 877,\n",
       "  'sending': 878,\n",
       "  'some': 879,\n",
       "  'perfectly': 880,\n",
       "  'configure': 881,\n",
       "  'spark': 882,\n",
       "  'headers': 883,\n",
       "  'proper': 884,\n",
       "  'ubuntu': 885,\n",
       "  'callback': 886,\n",
       "  'general': 887,\n",
       "  'suppose': 888,\n",
       "  'hash': 889,\n",
       "  'ip': 890,\n",
       "  'member': 891,\n",
       "  'along': 892,\n",
       "  'believe': 893,\n",
       "  'linq': 894,\n",
       "  'developer': 895,\n",
       "  'detect': 896,\n",
       "  'font': 897,\n",
       "  'disable': 898,\n",
       "  'logs': 899,\n",
       "  'searching': 900,\n",
       "  'definition': 901,\n",
       "  'strange': 902,\n",
       "  'greatly': 903,\n",
       "  'present': 904,\n",
       "  'creates': 905,\n",
       "  'scenario': 906,\n",
       "  'deploy': 907,\n",
       "  'h': 908,\n",
       "  'starts': 909,\n",
       "  'debugging': 910,\n",
       "  'force': 911,\n",
       "  'plot': 912,\n",
       "  'iis': 913,\n",
       "  'slow': 914,\n",
       "  'days': 915,\n",
       "  'although': 916,\n",
       "  'noticed': 917,\n",
       "  'relevant': 918,\n",
       "  'practice': 919,\n",
       "  'bytes': 920,\n",
       "  'amount': 921,\n",
       "  'navigation': 922,\n",
       "  'entry': 923,\n",
       "  'hope': 924,\n",
       "  'matter': 925,\n",
       "  'extract': 926,\n",
       "  'managed': 927,\n",
       "  'whenever': 928,\n",
       "  'allows': 929,\n",
       "  'compiled': 930,\n",
       "  'usage': 931,\n",
       "  'throws': 932,\n",
       "  'arrays': 933,\n",
       "  'learning': 934,\n",
       "  'appreciate': 935,\n",
       "  'attempt': 936,\n",
       "  'join': 937,\n",
       "  'f': 938,\n",
       "  'lambda': 939,\n",
       "  'share': 940,\n",
       "  'suggest': 941,\n",
       "  'instances': 942,\n",
       "  'wrote': 943,\n",
       "  'split': 944,\n",
       "  'platform': 945,\n",
       "  'active': 946,\n",
       "  'keyboard': 947,\n",
       "  'label': 948,\n",
       "  'others': 949,\n",
       "  'kernel': 950,\n",
       "  'extra': 951,\n",
       "  'operations': 952,\n",
       "  'nice': 953,\n",
       "  'third': 954,\n",
       "  'animation': 955,\n",
       "  'fragment': 956,\n",
       "  'determine': 957,\n",
       "  'components': 958,\n",
       "  'yes': 959,\n",
       "  'equivalent': 960,\n",
       "  'came': 961,\n",
       "  'docs': 962,\n",
       "  'bind': 963,\n",
       "  'confused': 964,\n",
       "  'below': 965,\n",
       "  'each': 966,\n",
       "  'free': 967,\n",
       "  'implementing': 968,\n",
       "  'fail': 969,\n",
       "  'efficient': 970,\n",
       "  'body': 971,\n",
       "  'computer': 972,\n",
       "  'removed': 973,\n",
       "  'undefined': 974,\n",
       "  'behind': 975,\n",
       "  'internal': 976,\n",
       "  'github': 977,\n",
       "  'engine': 978,\n",
       "  'easily': 979,\n",
       "  'merge': 980,\n",
       "  'by': 981,\n",
       "  'dictionary': 982,\n",
       "  'consider': 983,\n",
       "  'tasks': 984,\n",
       "  'specifically': 985,\n",
       "  'dataframe': 986,\n",
       "  'listview': 987,\n",
       "  'ssl': 988,\n",
       "  'steps': 989,\n",
       "  'while': 990,\n",
       "  'checking': 991,\n",
       "  'enable': 992,\n",
       "  'behaviour': 993,\n",
       "  'longer': 994,\n",
       "  'production': 995,\n",
       "  'success': 996,\n",
       "  'anyway': 997,\n",
       "  'camera': 998,\n",
       "  'comment': 999,\n",
       "  'entities': 1000,\n",
       "  ...})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings matrix\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "# Create embedding matrix using our vocabulary\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(TOKEN_COUNT, len(word_index))\n",
    "print(nb_words)\n",
    "\n",
    "# Random normal for missing entries\n",
    "# embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, EMBED_SIZE))\n",
    "# for word, i in word_index.items():\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None: \n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Zero for missing entries\n",
    "embedding_matrix = np.zeros((nb_words, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_matrix.shape, word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Elmo Embedding layer\n",
    "\n",
    "Here we load the Elmo embedding layer using Tensorflow Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rjurney/anaconda3/envs/weak/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rjurney/anaconda3/envs/weak/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "embeddings = elmo(\n",
    "    [\"the cat is on the mat\", \"dogs are in the fog\"],\n",
    "    signature=\"default\",\n",
    "    as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences,\n",
    "    labels,\n",
    "    test_size=TEST_SPLIT,\n",
    "    random_state=1337\n",
    ")\n",
    "\n",
    "# Conserve RAM\n",
    "del padded_sequences\n",
    "del labels\n",
    "gc.collect()\n",
    "\n",
    "assert(X_train.shape[0] == y_train.shape[0])\n",
    "assert(X_train.shape[1] == MAX_LEN)\n",
    "assert(X_test.shape[0] == y_test.shape[0]) \n",
    "assert(X_test.shape[1] == MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weight_vec = list(np.max(np.sum(y_train, axis=0)) / np.sum(y_train, axis=0))\n",
    "train_class_weights = {i: train_weight_vec[i] for i in range(y_train.shape[1])}\n",
    "\n",
    "test_weight_vec = list(np.max(np.sum(y_test, axis=0)) / np.sum(y_test, axis=0))\n",
    "test_class_weights = {i: test_weight_vec[i] for i in range(y_test.shape[1])}\n",
    "\n",
    "sorted(list(train_class_weights.items()), key=lambda x: x[1]), sorted(list(test_class_weights.items()), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Performance Log for the Model\n",
    "\n",
    "We will log the original performance as a reference point as well as the performance of the latest model to the current run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    simple_log\n",
    "except NameError:\n",
    "    simple_log = []\n",
    "\n",
    "try:\n",
    "    with open('simple_log.jsonl') as f:\n",
    "        for line in f:\n",
    "            simple_log.append(json.loads(line))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "SEQUENCE = simple_log[-1]['sequence'] if len(simple_log) > 0 else 0\n",
    "\n",
    "SEQUENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a Simple CNN Model to Classify Questions to their Corresponding Tags\n",
    "\n",
    "Now we’re ready to train a model to classify/label questions with tag categories. We start with a simple model with one `Conv1D`/`GlobalMaxPool1D`. We use the functional API and we’ve heavily parametrized the code so as to facilitate experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import binary_crossentropy, kld\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import lib.utils\n",
    "\n",
    "\n",
    "FILTER_COUNT        = 128\n",
    "FILTER_SIZE         = 3\n",
    "EPOCHS              = 8\n",
    "ACTIVATION          = 'selu'\n",
    "CONV_PADDING        = 'same'\n",
    "STRIDES             = 1\n",
    "EMBED_SIZE          = 300\n",
    "EMBED_DROPOUT_RATIO = 0.1\n",
    "CONV_DROPOUT_RATIO  = 0.1\n",
    "\n",
    "EXPERIMENT_NAME = 'simple_cnn_again'\n",
    "\n",
    "if len(simple_log) > 0 and EXPERIMENT_NAME == simple_log[-1]['name']:\n",
    "    print('RENAME YOUR EXPERIMENT')\n",
    "    raise Exception('RENAME YOUR EXPERIMENT')\n",
    "\n",
    "SEQUENCE += 1\n",
    "\n",
    "\n",
    "# Weights and Biases Monitoring\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "# wandb.init(project=\"weakly-supervised-learning\", name=EXPERIMENT_NAME)\n",
    "# config = wandb.config\n",
    "\n",
    "# config_dict = {\n",
    "#     'name': EXPERIMENT_NAME,\n",
    "#     'embedding': 'own',\n",
    "#     'architecture': 'Simple Conv1D',\n",
    "#     'epochs': EPOCHS,\n",
    "#     'batch_size': BATCH_SIZE,\n",
    "#     'filter_count': FILTER_COUNT,\n",
    "#     'filter_size': FILTER_SIZE,\n",
    "#     'activation': ACTIVATION,\n",
    "#     'conv_padding': CONV_PADDING,\n",
    "#     'sequence': SEQUENCE\n",
    "# }\n",
    "# print(config_dict)\n",
    "# config.update(\n",
    "#     config_dict\n",
    "# )\n",
    "\n",
    "titles = ['Own Embedding', 'Static GloVe', 'Retrained GloVe']\n",
    "embedding_layers = [\n",
    "    \n",
    "    # Randomly Initialized Embedding\n",
    "    Embedding(\n",
    "        TOKEN_COUNT,\n",
    "        EMBED_SIZE, \n",
    "        input_length=X_train.shape[1],\n",
    "        embeddings_initializer=RandomUniform(),\n",
    "    ),\n",
    "    \n",
    "    # Static transfer of GloVe embedding\n",
    "    Embedding(\n",
    "        TOKEN_COUNT,\n",
    "        EMBED_SIZE,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_LEN,\n",
    "        trainable=False\n",
    "    ),\n",
    "    \n",
    "    # Retraining of GloVe embedding\n",
    "    Embedding(\n",
    "        TOKEN_COUNT,\n",
    "        EMBED_SIZE,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_LEN,\n",
    "        trainable=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "for title, emb_layer in zip(titles, embedding_layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(emb_layer)\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(\n",
    "        Conv1D(\n",
    "            FILTER_COUNT, \n",
    "            FILTER_SIZE, \n",
    "            padding=CONV_PADDING, \n",
    "            activation=ACTIVATION, \n",
    "            strides=1\n",
    "        )\n",
    "    )\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(\n",
    "        Dense(\n",
    "            y_train.shape[1],\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            tf.keras.metrics.CategoricalAccuracy(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.TruePositives(),\n",
    "            tf.keras.metrics.FalsePositives(),\n",
    "            tf.keras.metrics.TrueNegatives(),\n",
    "            tf.keras.metrics.FalseNegatives(),\n",
    "        ]\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_categorical_accuracy',\n",
    "            factor=0.1,\n",
    "            patience=1,\n",
    "            verbose=1,\n",
    "        ), \n",
    "        EarlyStopping(\n",
    "            monitor='val_categorical_accuracy',\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "        ), \n",
    "        ModelCheckpoint(\n",
    "            filepath='models/cnn_tagger.weights.hdf5',\n",
    "            monitor='val_categorical_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        # WandbCallback()\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        class_weight=train_class_weights,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        validation_split=TEST_SPLIT,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    model = tf.keras.models.load_model('models/cnn_tagger.weights.hdf5')\n",
    "    metrics = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    log = {}\n",
    "    for name, val in zip(model.metrics_names, metrics):\n",
    "\n",
    "        repeat_name, py_val = lib.utils.fix_metric(name, val)\n",
    "        log[repeat_name] = py_val\n",
    "\n",
    "    # Add a name and sequence number and an F1 score\n",
    "    log.update({'name': title})\n",
    "    log.update({'sequence': SEQUENCE})\n",
    "    log.update({'f1': (log['precision'] * log['recall']) / (log['precision'] + log['recall'])})\n",
    "\n",
    "    simple_log.append(log)\n",
    "\n",
    "    # Overwrite the old log\n",
    "    with open('simple_log.jsonl', 'w') as f:\n",
    "        [f.write(json.dumps(l) + '\\n') for l in simple_log]\n",
    "\n",
    "pd.DataFrame(simple_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Epoch Accuracy\n",
    "\n",
    "We want to know the performance at each epoch so that we don't train needlessly large numbers of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "new_history = {}\n",
    "for key, metrics in history.history.items():\n",
    "    new_history[lib.utils.fix_metric_name(key)] = metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "\n",
    "viz_keys = ['val_categorical_accuracy', 'val_precision', 'val_recall']\n",
    "for key in viz_keys:\n",
    "    plt.plot(new_history[key])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(viz_keys, loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Kim-CNN Model to Label Stack Overflow Questions\n",
    "\n",
    "Once again we’re ready to train a model to classify/label questions with tag categories. The model is based on [Kim-CNN](https://arxiv.org/abs/1408.5882), a commonly used convolutional neural network for sentence and document classification. We use the functional API and we’ve heavily parametrized the code so as to facilitate experimentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Activation, Embedding, Flatten, MaxPool1D, GlobalMaxPool1D, \n",
    "    Dropout, Conv1D, Input, concatenate, Reshape\n",
    ")\n",
    "from tensorflow.keras.losses import binary_crossentropy, kld\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# from keras_radam import RAdam\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "EXPERIMENT_NAME = 'kim_cnn_2000_3_4_5_7_again_2'\n",
    "\n",
    "FILTER_COUNT        = 128\n",
    "FILTER_SIZE         = [3, 4, 5, 7]\n",
    "EPOCHS              = 8\n",
    "ACTIVATION          = 'selu'\n",
    "CONV_PADDING        = 'same'\n",
    "EMBED_SIZE          = 50\n",
    "EMBED_DROPOUT_RATIO = 0.1\n",
    "CONV_DROPOUT_RATIO  = 0.1\n",
    "\n",
    "if len(simple_log) > 0 and EXPERIMENT_NAME == simple_log[-1]['name']:\n",
    "    print('RENAME YOUR EXPERIMENT')\n",
    "    raise Exception('RENAME YOUR EXPERIMENT')\n",
    "\n",
    "SEQUENCE += 1\n",
    "\n",
    "# # Weights and Biases Monitoring\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "# wandb.init(project=\"weakly-supervised-learning\", name=EXPERIMENT_NAME)\n",
    "# config = wandb.config\n",
    "\n",
    "# config.update(\n",
    "#     {\n",
    "#         'name': EXPERIMENT_NAME,\n",
    "#         'embedding': 'own',\n",
    "#         'architecture': 'Kim CNN',\n",
    "#         'epochs': EPOCHS,\n",
    "#         'batch_size': BATCH_SIZE,\n",
    "#         'filter_count': FILTER_COUNT,\n",
    "#         'filter_size': FILTER_SIZE,\n",
    "#         'activation': ACTIVATION,\n",
    "#         'conv_padding': CONV_PADDING,\n",
    "#         'sequence': SEQUENCE\n",
    "#     }\n",
    "# )\n",
    "\n",
    "padded_input = Input(\n",
    "    shape=(X_train.shape[1],),\n",
    "    dtype='int32'\n",
    ")\n",
    "\n",
    "emb = Embedding(\n",
    "    TOKEN_COUNT, \n",
    "    EMBED_SIZE,\n",
    "    embeddings_initializer=RandomUniform(),\n",
    "    input_length=X_train.shape[1]\n",
    ")(padded_input)\n",
    "# emb = Embedding(\n",
    "#     TOKEN_COUNT,\n",
    "#     EMBED_SIZE,\n",
    "#     weights=[embedding_matrix],\n",
    "#     input_length=MAX_LEN,\n",
    "#     trainable=True,\n",
    "# )(padded_input)\n",
    "drp = Dropout(0.1)(emb)\n",
    "\n",
    "# Create convlutions of different sizes\n",
    "convs = []\n",
    "for filter_size in FILTER_SIZE:\n",
    "    f_conv = Conv1D(\n",
    "        filters=FILTER_COUNT,\n",
    "        kernel_size=filter_size,\n",
    "        padding=CONV_PADDING,\n",
    "        activation=ACTIVATION\n",
    "    )(drp)\n",
    "    f_shape = Reshape((MAX_LEN * EMBED_SIZE, 1))(f_conv)\n",
    "    # f_pool = GlobalMaxPool1D()(f_shape)\n",
    "    f_pool = MaxPool1D(filter_size)(f_conv)\n",
    "    convs.append(f_pool)\n",
    "\n",
    "l_merge = concatenate(convs, axis=1)\n",
    "l_conv = Conv1D(\n",
    "    128,\n",
    "    5,\n",
    "    activation=ACTIVATION\n",
    ")(l_merge)\n",
    "l_pool = GlobalMaxPool1D()(l_conv)\n",
    "l_flat = Flatten()(l_pool)\n",
    "l_drp  = Dropout(CONV_DROPOUT_RATIO)(l_flat)\n",
    "l_dense = Dense(\n",
    "    60,\n",
    "    activation=ACTIVATION\n",
    ")(l_drp)\n",
    "out_dense = Dense(\n",
    "    y_train.shape[1],\n",
    "    activation='sigmoid'\n",
    ")(l_dense)\n",
    "\n",
    "model = Model(inputs=padded_input, outputs=out_dense)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.TruePositives(),\n",
    "        tf.keras.metrics.FalsePositives(),\n",
    "        tf.keras.metrics.TrueNegatives(),\n",
    "        tf.keras.metrics.FalseNegatives(),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_categorical_accuracy',\n",
    "        factor=0.1,\n",
    "        patience=1,\n",
    "        verbose=1,\n",
    "    ), \n",
    "    EarlyStopping(\n",
    "        monitor='val_categorical_accuracy',\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    ), \n",
    "    ModelCheckpoint(\n",
    "        filepath='models/cnn_tagger.weights.hdf5',\n",
    "        monitor='val_categorical_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    # WandbCallback()\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    class_weight=train_class_weights,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/cnn_tagger.weights.hdf5')\n",
    "metrics = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = {}\n",
    "for name, val in zip(model.metrics_names, metrics):\n",
    "    \n",
    "    repeat_name, py_val = lib.utils.fix_metric(name, val)\n",
    "    log[repeat_name] = py_val\n",
    "\n",
    "# Add a name and sequence number and an F1 score\n",
    "log.update({'name': EXPERIMENT_NAME})\n",
    "log.update({'sequence': SEQUENCE})\n",
    "log.update({'f1': (log['precision'] * log['recall']) / (log['precision'] + log['recall'])})\n",
    "\n",
    "simple_log.append(log)\n",
    "\n",
    "# Overwrite the old log\n",
    "with open('simple_log.jsonl', 'w') as f:\n",
    "    [f.write(json.dumps(l) + '\\n') for l in simple_log]\n",
    "\n",
    "pd.DataFrame([log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "new_history = {}\n",
    "for key, metrics in history.history.items():\n",
    "    new_history[lib.utils.fix_metric_name(key)] = metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "\n",
    "viz_keys = ['val_categorical_accuracy', 'val_precision', 'val_recall']\n",
    "# summarize history for accuracy\n",
    "for key in viz_keys:\n",
    "    plt.plot(new_history[key])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('metric')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(viz_keys, loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8, forward=True)\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare this Run to the 1st and Previous Run\n",
    "\n",
    "To get an idea of performance we need to see where we started and where we just came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to original\n",
    "if len(simple_log) > 1:\n",
    "    d2 = simple_log[-1]\n",
    "    d1 = simple_log[0]\n",
    "else:\n",
    "    d1 = simple_log[0]\n",
    "    d2 = simple_log[0]\n",
    "log_diff_1 = {key: d2.get(key, 0) - d1.get(key, 0) for key in d1.keys() if key not in ['name', 'sequence']}\n",
    "log_diff_1['current'] = d2['name']\n",
    "log_diff_1['previous'] = d1['name']\n",
    "\n",
    "# Compare to last run\n",
    "if len(simple_log) > 1:\n",
    "    d1 = simple_log[-2]\n",
    "    d2 = simple_log[-1]\n",
    "else:\n",
    "    d1 = simple_log[0]\n",
    "    d2 = simple_log[0]\n",
    "    \n",
    "log_diff_2 = {key: d2.get(key, 0) - d1.get(key, 0) for key in d1.keys() if key not in ['name', 'sequence']}\n",
    "log_diff_2['current'] = d2['name']\n",
    "log_diff_2['previous'] = d1['name']\n",
    "\n",
    "df = pd.DataFrame.from_dict([log_diff_1, log_diff_2])\n",
    "cols = df.columns.tolist()\n",
    "cols.remove('previous')\n",
    "cols.remove('current')\n",
    "show_cols = ['previous', 'current'] + cols\n",
    "df[show_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Last 10 Experiments\n",
    "\n",
    "It can be helpful to see trends of performance among experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(simple_log)\n",
    "log_df['f1'] = (log_df['precision'] * log_df['recall']) / (log_df['precision'] + log_df['recall'])\n",
    "\n",
    "log_df[[\n",
    "    'sequence',\n",
    "    'name',\n",
    "    'loss',\n",
    "    'categorical_accuracy',\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1',\n",
    "    'auc',\n",
    "    'true_positives',\n",
    "    'false_positives',\n",
    "    'true_negatives',\n",
    "    'false_negatives',\n",
    "    'hinge',\n",
    "    'mean_absolute_error',\n",
    "]][0:10 if len(log_df) > 9 else len(log_df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Actual Prediction Outputs\n",
    "\n",
    "It is not enough to know theoretical performance. We need to see the actual output of the tagger at different confidence thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_COUNT = 1000\n",
    "\n",
    "X_test_text = tokenizer.sequences_to_texts(X_test[:TEST_COUNT])\n",
    "\n",
    "y_test_tags = []\n",
    "for row in y_test[:TEST_COUNT].tolist():\n",
    "    tags = [index_tag[str(i)] for i, col in enumerate(row) if col == 1]\n",
    "    y_test_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the threshold for classification\n",
    "\n",
    "This lets us see how well the model generalizes to labeling more classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFY_THRESHOLD = 0.5\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > CLASSIFY_THRESHOLD) * 1\n",
    "\n",
    "y_pred_tags = []\n",
    "for row in y_pred[:TEST_COUNT].tolist():\n",
    "    tags = [index_tag[str(i)] for i, col in enumerate(row) if col > CLASSIFY_THRESHOLD]\n",
    "    y_pred_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See How Far off we are per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(y_pred, 0).sum(axis=0) - y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Prediction Results\n",
    "\n",
    "It is better to view the results in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tests = []\n",
    "for x, y, z in zip(X_test_text, y_pred_tags, y_test_tags):\n",
    "    prediction_tests.append({\n",
    "        'Question': x,\n",
    "        'Actual': ' '.join(sorted(z)),\n",
    "        'Predictions': ' '.join(sorted(y)),\n",
    "    })\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "pd.DataFrame(prediction_tests)[['Question', 'Actual', 'Predictions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Big Finish\n",
    "\n",
    "That is the big finish!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
